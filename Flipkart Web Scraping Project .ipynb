{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530b468b-1380-4cf6-86d4-025742aafd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619561f-8fe4-4ed4-aba4-9d59158c14f2",
   "metadata": {},
   "source": [
    "# Retrieving data from flipkart web page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a4d3ff-e1fa-438f-9bd1-371c9cdfd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_url=\"https://www.flipkart.com/search?q=smart+lock&page=\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page=requests.get(base_url,headers=headers)\n",
    "#print(page)\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "#print(soup1) #show the whole page html data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27145a9-e4ad-48a0-b5ae-b665c9319c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.flipkart.com//search?q=smart+lock&page=2\n"
     ]
    }
   ],
   "source": [
    "# findind next page data \n",
    "url2=soup1.find(\"a\",class_=\"_9QVEpD\").get(\"href\")              # href=holds the link of next page\n",
    "next_page=\"https://www.flipkart.com/\"+url2                     # <a>=anchor tag\n",
    "print(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4ae612-74d4-4cb7-b875-3a57b3d9e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.flipkart.com//search?q=smart+lock&page=1\n",
      "https://www.flipkart.com//search?q=smart+lock&page=2\n",
      "https://www.flipkart.com//search?q=smart+lock&page=3\n",
      "https://www.flipkart.com//search?q=smart+lock&page=4\n",
      "https://www.flipkart.com//search?q=smart+lock&page=5\n",
      "https://www.flipkart.com//search?q=smart+lock&page=6\n",
      "https://www.flipkart.com//search?q=smart+lock&page=7\n",
      "https://www.flipkart.com//search?q=smart+lock&page=8\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10):\n",
    "    base_url=\"https://www.flipkart.com/search?q=smart+lock&page=\"+str(i)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    \n",
    "    page=requests.get(base_url,headers=headers)\n",
    "    #print(page)\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "    #print(soup1) #show the whole page html data\n",
    "    \n",
    "    # findind next page data \n",
    "    url=soup1.find(\"a\",class_=\"_9QVEpD\").get(\"href\")              # href=holds the link of next page\n",
    "    next_page=\"https://www.flipkart.com/\"+url                     # <a>=anchor tag\n",
    "    print(next_page)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f0278-7f79-4573-b15a-3bcdb85971f0",
   "metadata": {},
   "source": [
    "#  Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "997e7df2-0095-47dc-9306-c3b65a62b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "Brand_name=[]                                                                   #(String)\n",
    "Price=[]                                                                        #(Integer)\n",
    "Rating=[]                                                                       #(Float)\n",
    "Rating_count=[]                                                                 #(Integer)\n",
    "Review_count=[]                                                                 #(Integer)\n",
    "Ranking=[]                                                                      #(Integer)\n",
    "URL=[]                                                                          #(String)\n",
    "\n",
    "base_url=\"https://www.flipkart.com/search?q=smart+lock&page=\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page = requests.get(base_url, headers=headers)\n",
    "#print(page)\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "#print(soup1) #show the whole page html data\n",
    "box= soup1.find(\"div\",class_=\"DOjaWF gdgoEp\")\n",
    "\n",
    "#finding Brand name\n",
    "names = box.find_all('a',class_=\"wjcEIp\")\n",
    "for name in names:\n",
    "    Brand_name.append(name.get('title'))\n",
    "\n",
    "# print(Brand_name)\n",
    "\n",
    "#finding prices\n",
    "prices = box.find_all('div', class_=\"Nx9bqj\")\n",
    "for i in prices:\n",
    "    price_text = i.text.strip()\n",
    "    Price.append(price_text)\n",
    "#print(Price)\n",
    "\n",
    "# finding rating\n",
    "product_boxes = box.find_all('div', class_=\"slAVV4\")  \n",
    "for product_box in product_boxes:\n",
    "    rating = product_box.find('div', class_=\"XQDdHH\")\n",
    "    if rating:\n",
    "        Rating.append(rating.text.strip())\n",
    "    else:\n",
    "        Rating.append('null')\n",
    "#print(Rating)\n",
    "\n",
    "# Find rating count\n",
    "product_boxes = box.find_all('div', class_=\"slAVV4\") \n",
    "\n",
    "for product_box in product_boxes:\n",
    "    # Find the rating count within each product box\n",
    "    rating_count = product_box.find('span', class_=\"Wphh3N\")  \n",
    "    if rating_count:\n",
    "        Rating_count.append(rating_count.text.strip())\n",
    "    else:\n",
    "        Rating_count.append('null')\n",
    "\n",
    "print(Rating_count)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20977a5-c19d-49a5-952f-a2d21f4f4635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f11cad2-e8c9-46a7-8333-fc9c11c95012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 Reviews', '2 Reviews', 'null', '16 Reviews', '5 Reviews', '1 Reviews', '6 Reviews', 'null', '3 Reviews', '4 Reviews', 'null', 'null', '1 Reviews', '3 Reviews', 'null', '16 Reviews', 'null', 'null', 'null', 'null', '1 Reviews', 'null', 'null', 'null', '3 Reviews', 'null', '1 Reviews', '3 Reviews', 'null', 'null', 'null', 'null', '2 Reviews', 'null', '0 Reviews', '1 Reviews', 'null', 'null', 'null', 'null']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Lists to store scraped data\n",
    "Brand_name = []\n",
    "Price = []\n",
    "Rating = []\n",
    "Rating_count = []\n",
    "Review_count = []\n",
    "Ranking = []\n",
    "URL = []\n",
    "\n",
    "base_url = \"https://www.flipkart.com/search?q=smart+lock&page=\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\": \"gzip, deflate\", \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\": \"1\", \"Connection\": \"close\", \"Upgrade-Insecure-Requests\": \"1\"}\n",
    "\n",
    "# Fetch and parse the search results page\n",
    "page = requests.get(base_url, headers=headers)\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Find the container with product details\n",
    "box = soup1.find(\"div\", class_=\"DOjaWF gdgoEp\")\n",
    "\n",
    "# finding Review_count\n",
    "# Extract product URLs\n",
    "product_links = box.find_all('a', class_=\"wjcEIp\")\n",
    "for link in product_links:\n",
    "    product_url = link.get('href')\n",
    "    full_url = \"https://www.flipkart.com\" + product_url   # OR NEXT URL\n",
    "    URL.append(full_url)\n",
    "\n",
    "#print(URL)  \n",
    "\n",
    "def scrape_review_count(product_url):\n",
    "    try:\n",
    "        response = requests.get(product_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        review_section = soup.find_all('div', class_='row j-aW8Z')\n",
    "        \n",
    "        for section in review_section:\n",
    "            text = section.get_text(strip=True)\n",
    "            if \"Reviews\" in text:\n",
    "                return text\n",
    "        return 'null'\n",
    "    except Exception as e:\n",
    "        print(f\"Error while scraping {product_url}: {e}\")\n",
    "        return 'null'\n",
    "\n",
    "# Loop through the URLs and scrape review count\n",
    "for url in URL:\n",
    "    review_count = scrape_review_count(url)\n",
    "    Review_count.append(review_count)\n",
    "\n",
    "print(Review_count)  # To verify the review counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d454b23f-9435-4a64-aab2-571c29dfab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.flipkart.com//search?q=smart+lock&page=1\n",
      "https://www.flipkart.com//search?q=smart+lock&page=2\n",
      "https://www.flipkart.com//search?q=smart+lock&page=3\n",
      "https://www.flipkart.com//search?q=smart+lock&page=4\n",
      "https://www.flipkart.com//search?q=smart+lock&page=5\n",
      "https://www.flipkart.com//search?q=smart+lock&page=6\n",
      "https://www.flipkart.com//search?q=smart+lock&page=7\n",
      "https://www.flipkart.com//search?q=smart+lock&page=8\n",
      "https://www.flipkart.com//search?q=smart+lock&page=9\n",
      "https://www.flipkart.com//search?q=smart+lock&page=10\n",
      "https://www.flipkart.com//search?q=smart+lock&page=11\n",
      "https://www.flipkart.com//search?q=smart+lock&page=12\n",
      "https://www.flipkart.com//search?q=smart+lock&page=13\n",
      "https://www.flipkart.com//search?q=smart+lock&page=14\n",
      "https://www.flipkart.com//search?q=smart+lock&page=15\n",
      "https://www.flipkart.com//search?q=smart+lock&page=16\n",
      "https://www.flipkart.com//search?q=smart+lock&page=17\n",
      "https://www.flipkart.com//search?q=smart+lock&page=18\n",
      "https://www.flipkart.com//search?q=smart+lock&page=19\n",
      "https://www.flipkart.com//search?q=smart+lock&page=20\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import smtplib\n",
    "\n",
    "# Lists to store scraped data\n",
    "Brand_name = []\n",
    "Price = []\n",
    "Rating = []\n",
    "Rating_count = []\n",
    "Review_count = []\n",
    "Ranking = []\n",
    "URL = []\n",
    "\n",
    "for i in range(2,22):\n",
    "    base_url=\"https://www.flipkart.com/search?q=smart+lock&page=\"+str(i)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    \n",
    "    page=requests.get(base_url,headers=headers)\n",
    "    #print(page)\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "                                                    #print(soup1) #show the whole page html data\n",
    "    box= soup1.find(\"div\",class_=\"DOjaWF gdgoEp\")\n",
    "                                                 # print(box) #shows the paricular product containing html data \n",
    "    # findind next page data \n",
    "    url=soup1.find(\"a\",class_=\"_9QVEpD\").get(\"href\")                                             # href=holds the link of next page\n",
    "    next_page=\"https://www.flipkart.com/\"+url                                                    # <a>=anchor tag\n",
    "                                           #print(next_page)\n",
    "    \n",
    "    #finding Brand name\n",
    "    names = box.find_all('a',class_=\"wjcEIp\")\n",
    "    for name in names:\n",
    "        Brand_name.append(name.get('title'))\n",
    "    \n",
    "                                        # print(Brand_name)\n",
    "    \n",
    "    #finding prices\n",
    "    prices = box.find_all('div', class_=\"Nx9bqj\")\n",
    "    for i in prices:\n",
    "        price_text = i.text.strip()\n",
    "        Price.append(price_text)\n",
    "                                         #print(Price)\n",
    "    \n",
    "    # finding rating\n",
    "    product_boxes = box.find_all('div', class_=\"slAVV4\")  \n",
    "    for product_box in product_boxes:\n",
    "        rating = product_box.find('div', class_=\"XQDdHH\")\n",
    "        if rating:\n",
    "            Rating.append(rating.text.strip())\n",
    "        else:\n",
    "            Rating.append('null')\n",
    "                                     #print(Rating)\n",
    "    \n",
    "    # Find rating count\n",
    "    product_boxes = box.find_all('div', class_=\"slAVV4\") \n",
    "    \n",
    "    for product_box in product_boxes:\n",
    "        # Find the rating count within each product box\n",
    "        rating_count = product_box.find('span', class_=\"Wphh3N\")  \n",
    "        if rating_count:\n",
    "            Rating_count.append(rating_count.text.strip())\n",
    "        else:\n",
    "            Rating_count.append('null')\n",
    "    \n",
    "                                       #print(Rating_count)\n",
    "\n",
    "    print(next_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b091aa8b-719d-4d65-8622-5fb7e2ed63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Lists to store scraped data\n",
    "Brand_name = []\n",
    "Price = []\n",
    "Rating = []\n",
    "Rating_count = []\n",
    "Review_count = []\n",
    "Ranking = []\n",
    "URL = []\n",
    "\n",
    "# Headers for the HTTP request\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\",\"Accept-Encoding\": \"gzip, deflate\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\",\"DNT\": \"1\", \"Connection\": \"close\", \"Upgrade-Insecure-Requests\": \"1\"}\n",
    "\n",
    "def scrape_review_count(product_url):\n",
    "    try:\n",
    "        response = requests.get(product_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        review_section = soup.find_all('div', class_='row j-aW8Z')\n",
    "        \n",
    "        for section in review_section:\n",
    "            text = section.get_text(strip=True)\n",
    "            if \"Reviews\" in text:\n",
    "                return text\n",
    "        return 'null'\n",
    "    except Exception as e:\n",
    "        print(f\"Error while scraping {product_url}: {e}\")\n",
    "        return 'null'\n",
    "rank = 1\n",
    "for i in range(2, 8):\n",
    "    base_url = f\"https://www.flipkart.com/search?q=smart+lock&page={i}\"\n",
    "    page = requests.get(base_url, headers=headers)\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    box = soup1.find(\"div\", class_=\"DOjaWF gdgoEp\")\n",
    "    \n",
    "    # Finding brand names\n",
    "    names = box.find_all('a', class_=\"wjcEIp\")\n",
    "    for name in names:\n",
    "        Brand_name.append(name.get('title'))\n",
    "    \n",
    "    # Finding prices\n",
    "    prices = box.find_all('div', class_=\"Nx9bqj\")\n",
    "    for price in prices:\n",
    "        price_text = price.text.strip()\n",
    "        Price.append(price_text)\n",
    "        \n",
    "    # Finding ratings and rating counts\n",
    "    product_boxes = box.find_all('div', class_=\"slAVV4\")\n",
    "    for product_box in product_boxes:\n",
    "        # Finding ratings\n",
    "        rating = product_box.find('div', class_=\"XQDdHH\")\n",
    "        if rating:\n",
    "            Rating.append(rating.text.strip())\n",
    "        else:\n",
    "            Rating.append('null')\n",
    "        # Finding rating counts\n",
    "        rating_count = product_box.find('span', class_=\"Wphh3N\")\n",
    "        if rating_count:\n",
    "            Rating_count.append(rating_count.text.strip())\n",
    "        else:\n",
    "            Rating_count.append('null')\n",
    "\n",
    "        \n",
    "    # Scraping rank and Extracting product URLs\n",
    "    product_links = box.find_all('a', class_=\"wjcEIp\")\n",
    "    for link in product_links:\n",
    "        product_url = link.get('href')\n",
    "        full_url = \"https://www.flipkart.com\" + product_url\n",
    "        URL.append(full_url)\n",
    "        Ranking.append(rank)\n",
    "        rank += 1\n",
    "\n",
    "\n",
    "# Loop through the URLs and scrape review count\n",
    "for url in URL:\n",
    "    review_count = scrape_review_count(url)\n",
    "    Review_count.append(review_count)\n",
    "\n",
    "# print(Brand_name)\n",
    "# print(len(Brand_name))\n",
    "# print(Price)\n",
    "# print(len(Price))\n",
    "# print(Rating)\n",
    "# print(len(Rating))\n",
    "# print(Rating_count)\n",
    "# print(len(Rating_count))\n",
    "#print(Review_count)\n",
    "#print(len(Review_count))\n",
    "#print(Ranking) \n",
    "#print(len(Ranking))\n",
    "# print(URL)\n",
    "# print(len(URL))\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "data = {\n",
    "    'Brand_name': Brand_name,\n",
    "    'Price': Price,\n",
    "    'Rating': Rating,\n",
    "    'Rating_count': Rating_count,\n",
    "    'Review_count': Review_count,\n",
    "    'Ranking': Ranking,\n",
    "    'URL': URL\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# Save the DataFrame to a CSV file\n",
    "\n",
    "df.to_csv(r'F:\\python folder\\Flipkart Web Scraping\\smart_lock_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
